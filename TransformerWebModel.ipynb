{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptacion de modelo tomado de https://apmonitor.com/dde/index.php/Main/LLMTransformers con datos de Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension del dataframe: (1, 4875)\n",
      "Primer elemento del dataframe: 1242.7740478515625\n"
     ]
    }
   ],
   "source": [
    "#Carguemos los datos\n",
    "import pandas as pd\n",
    "ShanghaiDat=pd.read_csv('Shanghai-2005-2025.csv')\n",
    "ShanghaiDat=ShanghaiDat.drop(ShanghaiDat.columns[0], axis=1) #Eliminar la primera columna que tiene la etiqueta\n",
    "\n",
    "print('Dimension del dataframe:',ShanghaiDat.shape)\n",
    "print('Primer elemento del dataframe:',ShanghaiDat.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de Shanghai_epocas: (4865, 10)\n",
      "Shape de Shanghai_targets: (4865,)\n",
      "[3236.03198242 3241.82104492 3244.37792969 3242.62304688 3213.62402344\n",
      " 3230.1640625  3252.62597656 3250.60107422 3229.48803711 3270.65893555]\n"
     ]
    }
   ],
   "source": [
    "#Nos saltamos la parte del codigo que genera datos porque nosotros ya tenemos datos reales\n",
    "#Debemos convertir nuestros datos en una ventana de datos deslizantes. Esto es, obtener una matriz dividiendo los datos en epocas de 10 dias y obtener los target para cada una de esas epocas\n",
    "import numpy as np\n",
    "\n",
    "# Convertimos los datos a un array de 1 dimension\n",
    "ShanghaiDat = np.array(ShanghaiDat).flatten()\n",
    "\n",
    "#Dividimos en epocas de 10 dias\n",
    "def Epocas(sequence_length=10):\n",
    "    size = len(ShanghaiDat) \n",
    "    sequences = [ShanghaiDat[i:i+sequence_length] for i in range(size-sequence_length)]\n",
    "    next_points = ShanghaiDat[sequence_length:]\n",
    "\n",
    "    # Convertir a NumPy arrays correctamente\n",
    "    return np.array(sequences), np.array(next_points)\n",
    "\n",
    "Shanghai_epocas, Shanghai_targets = Epocas()\n",
    "\n",
    "print('Shape de Shanghai_epocas:', Shanghai_epocas.shape)\n",
    "print('Shape de Shanghai_targets:', Shanghai_targets.shape)\n",
    "\n",
    "#Ahora tenemos 4865 epocas de 10 dias en una variable, y en la otra varibale todos los targets de cada epoca. Es importante señalar que ninguna epoca puede contener a su target\n",
    "#Es por ello que en la ultima epoca solo se llega al penultimo valor\n",
    "print(Shanghai_epocas[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Despues necesitamos definir una clase que permita tratar los datos para poder usar DataLoader de pytorch.\n",
    "#Terminamos de cargar todas las librerias que vamos a usar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset): #Heredamos caracteristicas de Dataset\n",
    "    def __init__(self, sequences, next_points): #Determina que parametros debemos pasar la crear una instancia\n",
    "        self.sequences = sequences\n",
    "        self.next_points = next_points\n",
    "\n",
    "    def __len__(self): #Nos dice la longitud de nuestros datos de secuancia\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx): #Nos da cualquier epoca que queramos y su targeta asociado\n",
    "        return self.sequences[idx], self.next_points[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3236.03198242, 3241.82104492, 3244.37792969, 3242.62304688,\n",
       "        3213.62402344, 3230.1640625 , 3252.62597656, 3250.60107422,\n",
       "        3229.48803711, 3270.65893555]),\n",
       " np.float64(3303.6669921875))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probamos crear una instancia con nuestros datos\n",
    "Datos=TimeSeriesDataset(Shanghai_epocas, Shanghai_targets)\n",
    "print(len(Datos))\n",
    "Datos[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model (simplified for numerical data)\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size=1, sequence_length=10, num_layers=1, num_heads=2, dim_feedforward=512): #Se definen los parametros del modelo. Una capa, 2 cabezas de atencion\n",
    "        super(TransformerModel, self).__init__() #Llama al init de la clase padre, que es el constructor del modelo. Es necesario para crear modelos personalizados\n",
    "        self.sequence_length = sequence_length\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size*sequence_length, nhead=num_heads, dim_feedforward=dim_feedforward) #Define una capa\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers) #Crea el transformer con definido anteriormente\n",
    "        self.fc_out = nn.Linear(input_size * sequence_length, 1) #Capa fully connected que toma la salida del trandormer (15 valores) y regresa un unico valor (prediccion, next point)\n",
    "\n",
    "    \n",
    "    #Aqui se define como fluye la informacion a traves del modelo. Pasar datos por la red y obtener predicciones\n",
    "    def forward(self, src): #src es el tensor de entrada\n",
    "        # Reshape to match the input dimensions\n",
    "        src = src.reshape(-1, self.sequence_length, 1)  #-1 hace que se ajuste automaticamente el tamaño del batch\n",
    "        src = src.flatten(start_dim=1) #Aplana la dimension 1D\n",
    "        src = src.unsqueeze(0)  # Add batch dimension *\n",
    "        out = self.transformer_encoder(src) #Aplica el modelo en la secuencia\n",
    "        out = out.squeeze(0)  # Remove batch dimension *\n",
    "        return self.fc_out(out) #Le aplica la capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datos\n",
    "sequences, next_points = Epocas() #Cargamos nuestras epocas de 15 dias(Shanghai_epocas) y nuestros target (Shanghai_targets)\n",
    "dataset = TimeSeriesDataset(sequences, next_points) #Asignamos las funciones a nuestros datos para poder manipularlos\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True) #Divide los datos en batches y los revuelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio Rojas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1670206.0\n",
      "Epoch 2, Loss: 12443139.0\n",
      "Epoch 3, Loss: 5482061.0\n",
      "Epoch 4, Loss: 1488125.75\n",
      "Epoch 5, Loss: 5165007.5\n",
      "Epoch 6, Loss: 10512810.0\n",
      "Epoch 7, Loss: 3198289.5\n",
      "Epoch 8, Loss: 9082861.0\n",
      "Epoch 9, Loss: 4491235.0\n",
      "Epoch 10, Loss: 9394131.0\n",
      "Epoch 11, Loss: 4991873.0\n",
      "Epoch 12, Loss: 3776616.75\n",
      "Epoch 13, Loss: 7387838.5\n",
      "Epoch 14, Loss: 8273649.5\n",
      "Epoch 15, Loss: 7123804.5\n",
      "Epoch 16, Loss: 7048106.0\n",
      "Epoch 17, Loss: 2852552.75\n",
      "Epoch 18, Loss: 2996812.0\n",
      "Epoch 19, Loss: 8560142.0\n",
      "Epoch 20, Loss: 8639546.0\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "model = TransformerModel() #Se llama al modelo definido\n",
    "criterion = nn.MSELoss() #Funcion de perdida\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #Optimizador\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):  # Numero de epocas, esto es numero de veces que todos los datos pasan por el modelo\n",
    "    for seq, next_point in dataloader: #Itera a traves de los batches\n",
    "        seq, next_point = seq.float(), next_point.float().unsqueeze(1) #Pone los datos en forma decimal \n",
    "        output = model(seq) #Se pasan las secuencias al modelo para obtener la prediccion output\n",
    "        loss = criterion(output, next_point) #Se calcula la perdida \n",
    "        optimizer.zero_grad() #Se limpian los gredientes de la iteracion anterior\n",
    "        loss.backward() #Back propagation. Gradientes de la perdida con respecto a los pesos y bias\n",
    "        optimizer.step() #Actualiza los parametros del modelo con base en los gradientes\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores usados para la prediccion: [1242.77404785 1251.93701172 1239.43005371 1244.74597168 1252.40100098\n",
      " 1257.46203613 1256.92297363 1256.31396484 1245.61999512 1216.65197754]\n",
      "Prediccion(dato siguiente): 394.0807189941406\n",
      "Dato siguiente real: 1251.93701171875\n"
     ]
    }
   ],
   "source": [
    "#Veamos como predice el modelo\n",
    "test_seq = torch.tensor(sequences[0]).float()\n",
    "predicted_point = model(test_seq)\n",
    "print('Valores usados para la prediccion:',sequences[0])\n",
    "print(\"Prediccion(dato siguiente):\", predicted_point.item())\n",
    "print('Dato siguiente real:',sequences[1,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
